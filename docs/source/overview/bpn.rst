反向传播(BPN)
=============

反向传播（BPN）算法是神经网络中研究最多、使用最多的算法之一，它用于将输出层中的误差传播到隐藏层的神经元，然后用于更新权重。

学习 BPN 算法可以分成以下两个过程：
- 正向传播：输入被馈送到网络，信号从输入层通过隐藏层传播到输出层。在输出层，计算误差和损失函数。
- 反向传播：在反向传播中，首先计算输出层神经元损失函数的梯度，然后计算隐藏层神经元损失函数的梯度。接下来用梯度更新权重。


数学推理
::::::::

首先给网络提供 M 个训练对（X，Y），X 为输入，Y 为期望的输出。输入通过激活函数 g(h) 和隐藏层传播到输出层。输出 Yhat 是网络的输出，得到 error=Y-Yhat。其损失函数 J(W) 如下：

.. image:: /_static/imgs/overview/bpn1.png

其中，i 取遍所有输出层的神经元（1 到 N）。然后可以使用 J(W) 的梯度并使用链式法则求导，来计算连接第 i 个输出层神经元到第 j 个隐藏层神经元的权重 Wij 的变化：

.. image:: /_static/imgs/overview/bpn2.png

这里，Oj 是隐藏层神经元的输出，h 表示隐藏层的输入值。这很容易理解，但现在怎么更新连接第 n 个隐藏层的神经元 k 到第 n+1 个隐藏层的神经元 j 的权值 Wjk？过程是相同的：将使用损失函数的梯度和链式法则求导，但这次计算 Wjk：

.. image:: /_static/imgs/overview/bpn3.png

代码实现
::::::::

